\chapter{Theoretical Background}
\label{chap:theoretical_background}

This chapter outlines the conceptual and scientific foundations relevant to the development of an XR-based assistance system for industrial workers. It introduces key technologies, principles of ergonomics, human-machine interaction modalities, and architectural tools that enable real-time support in complex environments.

\section{Extended Reality in Industrial Contexts}

Extended Reality (XR) technologies—encompassing Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR) are increasingly being explored beyond their origins in gaming and entertainment. In recent years, they have shown significant promise for applications in healthcare, education, training, and particularly in industrial environments. These immersive systems offer novel ways to visualize information, monitor surroundings, and interact with complex machinery or digital twins in real time.

In industrial settings, XR can bridge the gap between human workers and automated systems by enhancing spatial awareness, reducing cognitive load, and supporting ergonomically sound behavior. By embedding visualizations directly into the user's perceptual field and supplementing them with spatially anchored cues or haptic feedback, XR opens new pathways for context-sensitive assistance. This is especially relevant in environments that involve repetitive tasks, heavy machinery, or dynamic hazards—scenarios in which traditional safety protocols may fall short.

This section introduces the conceptual foundations of XR, outlines its most common industrial applications, and discusses the key challenges and opportunities associated with deploying XR systems in real-world industrial settings.

\subsection{Definition and Taxonomy}

Extended Reality (XR) is an umbrella term encompassing a spectrum of technologies that combine or replace real-world perception with computer-generated input. The conceptual foundation for this spectrum was introduced by Milgram and Kishino in their seminal work on Mixed Reality visual displays \cite{milgram1994taxonomy}.

At the core of their model lies the \textit{Reality–Virtuality Continuum}, which represents a scale between the completely real environment and the fully virtual environment. Technologies within this continuum can be classified as follows:

\begin{itemize}
    \item \textbf{Real Environment (RE):} The physical world, unmediated by digital augmentation.
    
    \item \textbf{Augmented Reality (AR):} Systems that overlay virtual elements onto the real world while maintaining real-time interaction and correct spatial registration. Examples include visual annotations or digital twins of industrial machinery displayed through XR headsets.
    
    \item \textbf{Mixed Reality (MR):} A broader concept encompassing AR, but also allowing for deeper integration where virtual and real elements interact and are spatially and temporally consistent. In MR, digital and physical objects can influence each other.
    
    \item \textbf{Augmented Virtuality (AV):} Mostly virtual environments that incorporate some real-world data—such as sensor streams or camera feeds.
    
    \item \textbf{Virtual Reality (VR):} Fully immersive digital environments with little or no real-world input.
\end{itemize}

XR, as used in this thesis, refers to the entire continuum and highlights systems that combine immersive visualization (e.g., via head-mounted displays) with real-world input data (e.g., motion capture, spatial localization, physiological sensors). This definition is especially relevant in safety-critical industrial contexts, where virtual feedback must accurately reflect physical risks and user behavior in real time.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{Graphics/Continuum.png}
    \caption{The Reality–Virtuality Continuum, adapted from Milgram and Kishino \cite{milgram1994taxonomy}.}
    \label{fig:reality_virtuality_continuum}
\end{figure}

\subsection{Applications of XR in Industry}


\subsection{Challenges and Opportunities}

\section{Human Factors and Ergonomics}
\subsection{Principles of Ergonomic Design}

\subsection{Common Industrial Posture-Related Injuries}

\subsection{Need for Real-Time Monitoring}

\section{Wearable Technologies for Assistance}
\subsection{Overview of Industrial Wearables}

\subsection{The Teslasuit}

\subsection{Capabilities and Limitations}

\section{Haptic Feedback and Multimodal Warning Systems}
\subsection{Perception of Haptic Stimuli}

\subsection{Design Principles for Effective Feedback}

\subsection{Visual vs. Haptic Alerts}

\subsection{Cognitive Load and Safety Feedback}

\section{Spatial Awareness and Localization in XR}
\subsection{XR Tracking Technologies}

\subsection{The Meta Quest 3}

\subsection{Spatial Consistency with Teslasuit Data}

\section{Multisensor Integration and Synchronization}
\subsection{Challenges in Multimodal Systems}

\subsection{LabStreamingLayer (LSL)}

\subsection{Integration of MQTT and Environment Data}

\section{Related Work}

