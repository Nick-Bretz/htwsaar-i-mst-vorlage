\chapter{Theoretical Background}
\label{chap:theoretical_background}

This chapter outlines the conceptual and scientific foundations relevant to the development of an XR-based assistance system for industrial workers. It introduces key technologies, principles of ergonomics, human-machine interaction modalities, and architectural tools that enable real-time support in complex environments.

\section{Extended Reality in Industrial Contexts}
\subsection{Definition and Taxonomy}

Extended Reality (XR) is an umbrella term encompassing a spectrum of technologies that combine or replace real-world perception with computer-generated input. The conceptual foundation for this spectrum was introduced by Milgram and Kishino in their seminal work on Mixed Reality visual displays \cite{milgram1994taxonomy}.

At the core of their model lies the \textit{Reality–Virtuality Continuum}, which represents a scale between the completely real environment and the fully virtual environment. Technologies within this continuum can be classified as follows:

\begin{itemize}
    \item \textbf{Real Environment (RE):} The physical world, unmediated by digital augmentation.
    
    \item \textbf{Augmented Reality (AR):} Systems that overlay virtual elements onto the real world while maintaining real-time interaction and correct spatial registration. Examples include visual annotations or digital twins of industrial machinery displayed through XR headsets.
    
    \item \textbf{Mixed Reality (MR):} A broader concept encompassing AR, but also allowing for deeper integration where virtual and real elements interact and are spatially and temporally consistent. In MR, digital and physical objects can influence each other.
    
    \item \textbf{Augmented Virtuality (AV):} Mostly virtual environments that incorporate some real-world data—such as sensor streams or camera feeds.
    
    \item \textbf{Virtual Reality (VR):} Fully immersive digital environments with little or no real-world input.
\end{itemize}

XR, as used in this thesis, refers to the entire continuum and highlights systems that combine immersive visualization (e.g., via head-mounted displays) with real-world input data (e.g., motion capture, spatial localization, physiological sensors). This definition is especially relevant in safety-critical industrial contexts, where virtual feedback must accurately reflect physical risks and user behavior in real time.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{Graphics/Continuum.png}
    \caption{The Reality–Virtuality Continuum, adapted from Milgram and Kishino \cite{milgram1994taxonomy}.}
    \label{fig:reality_virtuality_continuum}
\end{figure}

\subsection{Applications of XR in Industry}


\subsection{Challenges and Opportunities}

\section{Human Factors and Ergonomics}
\subsection{Principles of Ergonomic Design}

\subsection{Common Industrial Posture-Related Injuries}

\subsection{Need for Real-Time Monitoring}

\section{Wearable Technologies for Assistance}
\subsection{Overview of Industrial Wearables}

\subsection{The Teslasuit}

\subsection{Capabilities and Limitations}

\section{Haptic Feedback and Multimodal Warning Systems}
\subsection{Perception of Haptic Stimuli}

\subsection{Design Principles for Effective Feedback}

\subsection{Visual vs. Haptic Alerts}

\subsection{Cognitive Load and Safety Feedback}

\section{Spatial Awareness and Localization in XR}
\subsection{XR Tracking Technologies}

\subsection{The Meta Quest 3}

\subsection{Spatial Consistency with Teslasuit Data}

\section{Multisensor Integration and Synchronization}
\subsection{Challenges in Multimodal Systems}

\subsection{LabStreamingLayer (LSL)}

\subsection{Integration of MQTT and Environment Data}

\section{Related Work}

